# Introduction
In this repository, I am building several algorithm from scratch. I found the best way to learn for me is to build with my own hands, try to break and tweak code, and then observe behaviour. You will currently find these projects here:
- <b>Performance of policy gradient algorithms</b>. In this project, I was interested what the empirical and implementation lessons where when repeatedly implementing the vanilla policy gradient (VPG) and proximal policy optimisation (PPO) algorithm. I wanted to see how they performed in different environments and how competitive the vanilla algorithm could be made in comparison to its supposedly superior counterpart.
